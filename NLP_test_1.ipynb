{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7f318db4",
      "metadata": {
        "id": "7f318db4"
      },
      "source": [
        "##### NLTK (Natural Language Toolkit)\n",
        "\n",
        "    - How do you tokenize a sentence into words using NLTK?\n",
        "    \n",
        "pip install nltk\n",
        "\n",
        "Import the function and tokenize a sentence:\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = \"Hello! How are you doing today?\"\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "print(words)\n",
        "\n",
        "\n",
        "    - How do you remove stopwords from a text using NLTK?\n",
        "    pip install nltk\n",
        "\n",
        "Download the stopwords list (only once):\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "Remove stopwords from text:\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = \"This is an example sentence to demonstrate stopword removal.\"\n",
        "words = word_tokenize(sentence)  # Tokenize the sentence\n",
        "\n",
        "stop_words = set(stopwords.words('english'))  # Get the list of stopwords\n",
        "\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]  \n",
        "\n",
        "print(filtered_words)\n",
        "\n",
        "    - How do you perform stemming in NLTK? Provide an example.\n",
        "\n",
        "    Stemming is the process of reducing words to their root form. In NLTK, we use the PorterStemmer to do this.\n",
        "\n",
        "    pip install nltk\n",
        "\n",
        "    from nltk.stem import PorterStemmer\n",
        "\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "words = [\"running\", \"flies\", \"easily\", \"happiness\", \"studies\"]\n",
        "\n",
        "\n",
        "stemmed_words = [ps.stem(word) for word in words]\n",
        "\n",
        "print(stemmed_words)\n",
        "\n",
        "\n",
        "    - What is the difference between stemming and lemmatization in NLTK?\n",
        "    Stemming and lemmatization are both techniques to reduce words to their\n",
        "     base form, but they differ in their approach and results:\n",
        "     1. Stemming:\n",
        "Approach: Stemming simply removes prefixes or suffixes from words to reduce them to their root form, often based on rules or patterns.\n",
        "Result: The result might not always be a valid word in the language, just a \"stem.\"\n",
        "Example:\n",
        "\"running\" → \"run\"\n",
        "\"flies\" → \"fli\"\n",
        "\"better\" → \"better\"\n",
        "Tools in NLTK: PorterStemmer, SnowballStemmer\n",
        "2. Lemmatization:\n",
        "Approach: Lemmatization uses a dictionary and context to convert words to their base form (called a \"lemma\"), ensuring the result is a valid word in the language.\n",
        "Result: The output is a valid dictionary word, and the process is context-sensitive.\n",
        "Example:\n",
        "\"running\" → \"run\" (because it’s a verb)\n",
        "\"flies\" → \"fly\" (plural noun → singular noun)\n",
        "\"better\" → \"good\" (comparative → base form)\n",
        "Tools in NLTK: WordNetLemmatizer\n",
        "\n",
        "\n",
        "    - How do you perform part-of-speech (POS) tagging using NLTK?\n",
        "  Part-of-Speech (POS) tagging involves identifying the grammatical category\n",
        "  (noun, verb, adjective, etc.) of each word in a sentence. In NLTK, you can easily perform POS tagging using the built-in pos_tag function.\n",
        "\n",
        "Steps to Perform POS Tagging:\n",
        "\n",
        "Install NLTK (if not installed):\n",
        "\n",
        "pip install nltk\n",
        "\n",
        "Import necessary components and perform POS tagging:\n",
        "\n",
        "import nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk import pos_tag\n",
        "\n",
        "\n",
        "# Make sure to download necessary NLTK resources (only once)\n",
        "\n",
        "nltk.download('punkt')  # Tokenizer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')  # POS tagger\n",
        "\n",
        "\n",
        "sentence = \"NLTK is a powerful tool for text processing.\"\n",
        "\n",
        "words = word_tokenize(sentence)  # Tokenize the sentence\n",
        "\n",
        "pos_tags = pos_tag(words)  # Perform POS tagging\n",
        "\n",
        "\n",
        "print(pos_tags)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d242598",
      "metadata": {
        "id": "4d242598"
      },
      "source": [
        "##### spaCy\n",
        "    \n",
        "    -How do you load an English language model in spaCy?\n",
        "\n",
        "    install spaCy (if not installed):\n",
        "\n",
        "\n",
        "pip install spacy\n",
        "\n",
        "Download the English language model\n",
        "\n",
        "\n",
        "python -m spacy download en_core_web_sm\n",
        "\n",
        "en_core_web_sm: A small model (fast, but less accurate).\n",
        "\n",
        "Other models: en_core_web_md (medium size), en_core_web_lg (large size).\n",
        "Load the model in your code:\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# Process a text\n",
        "\n",
        "doc = nlp(\"spaCy is an amazing library for NLP!\")\n",
        "\n",
        "\n",
        "\n",
        "# Iterate through the processed tokens\n",
        "\n",
        "for token in doc:\n",
        "\n",
        "    print(token.text, token.pos_)\n",
        "\n",
        "    print(token.text, token.pos_)\n",
        "\n",
        "    -How do you extract named entities (NER) from a text using spaCy?\n",
        "    To extract Named Entities (NER) from a text using spaCy, you can use the ents attribute of a processed document. Here's a simple way to do it:\n",
        "\n",
        "Steps to Extract Named Entities:\n",
        "\n",
        "Install spaCy (if not installed):\n",
        "\n",
        "\n",
        "pip install spacy\n",
        "\n",
        "Download the English language model (if not downloaded yet):\n",
        "\n",
        "python -m spacy download en_core_web_sm\n",
        "\n",
        "Load the model and extract NER:\n",
        "\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# Process a text\n",
        "\n",
        "doc = nlp(\"Barack Obama was born in Hawaii and became the President of the United States.\")\n",
        "\n",
        "# Extract named entities\n",
        "\n",
        "for ent in doc.ents:\n",
        "\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "\n",
        "    -How do you find the dependency relations between words using spaCy?\n",
        "    import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"spaCy is an amazing library for natural language processing.\")\n",
        "\n",
        "# Visualize the dependency relations\n",
        "\n",
        "displacy.render(doc, style=\"dep\")\n",
        "\n",
        "    -How do you perform sentence segmentation in spaCy?\n",
        "    import spacy\n",
        "\n",
        "# Load the English language model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# Process the text\n",
        "\n",
        "doc = nlp(\"Hello! How are you doing today? I hope you're having a great time.\")\n",
        "\n",
        "# Segment into sentences\n",
        "\n",
        "for sent in doc.sents:\n",
        "\n",
        " print(sent.text)\n",
        "    -How do you check if a word is a stopword in spaCy?\n",
        "    import spacy\n",
        "\n",
        "\n",
        "# Load the English language model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# Process a text\n",
        "\n",
        "doc = nlp(\"This is a sample sentence for checking stopwords.\")\n",
        "\n",
        "\n",
        "# Check if each word is a stopword\n",
        "\n",
        "for token in doc:\n",
        "\n",
        "    print(token.text, \"is stopword:\", token.is_stop)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac7a422e",
      "metadata": {
        "id": "ac7a422e"
      },
      "source": [
        "##### TextBlob\n",
        "\n",
        "    -How do you compute the sentiment polarity of a text using TextBlob?\n",
        "\n",
        "    pip install textblob\n",
        "\n",
        "    from textblob import TextBlob\n",
        "\n",
        "\n",
        "# Sample text\n",
        "\n",
        "text = \"I love programming, but it can sometimes be frustrating.\"\n",
        "\n",
        "\n",
        "# Create a TextBlob object\n",
        "\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Get the sentiment polarity and subjectivity\n",
        "\n",
        "polarity, subjectivity = blob.sentiment\n",
        "\n",
        "print(f\"Polarity: {polarity}\")\n",
        "\n",
        "print(f\"Subjectivity: {subjectivity}\")\n",
        "\n",
        "\n",
        "    -How do you perform spelling correction using TextBlob?\n",
        "\n",
        "    pip install textblob\n",
        "\n",
        "    from textblob import TextBlob\n",
        "\n",
        "# Sample text with spelling errors\n",
        "\n",
        "text = \"I hav a beautifull gardn and I lovee it.\"\n",
        "\n",
        "\n",
        "# Create a TextBlob object\n",
        "\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Correct the spelling\n",
        "\n",
        "corrected_text = blob.correct()\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "\n",
        "print(\"Corrected Text:\", corrected_text)\n",
        "\n",
        "    -How do you get noun phrases from a sentence using TextBlob?\n",
        "    \n",
        "    pip install textblob\n",
        "\n",
        "    from textblob import TextBlob\n",
        "\n",
        "# Sample sentence\n",
        "\n",
        "sentence = \"The quick brown fox jumped over the lazy dog.\"\n",
        "\n",
        "\n",
        "# Create a TextBlob object\n",
        "\n",
        "blob = TextBlob(sentence)\n",
        "\n",
        "\n",
        "\n",
        "# Extract noun phrases\n",
        "\n",
        "noun_phrases = blob.noun_phrases\n",
        "\n",
        "print(\"Noun Phrases:\", noun_phrases)\n",
        "\n",
        "\n",
        "\n",
        "    -How do you translate a text from English to another language using TextBlob?\n",
        "\n",
        "    pip install textblob\n",
        "\n",
        "    from textblob import TextBlob\n",
        "\n",
        "# Sample sentence\n",
        "\n",
        "sentence = \"The quick brown fox jumped over the lazy dog.\"\n",
        "\n",
        "# Create a TextBlob object\n",
        "\n",
        "blob = TextBlob(sentence)\n",
        "\n",
        "# Extract noun phrases\n",
        "\n",
        "noun_phrases = blob.noun_phrases\n",
        "\n",
        "print(\"Noun Phrases:\", noun_phrases)\n",
        "\n",
        "    -How do you detect the language of a given text using TextBlob?\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "abe386c6",
      "metadata": {
        "id": "abe386c6"
      },
      "source": [
        "\n",
        "Text= Rani Chennamma was the queen of Kittur, a princely state in present-day Karnataka, India. She is remembered as one of the earliest Indian rulers to fight against British colonial rule. Born in 1778, she was well-trained in horse riding, sword fighting, and archery. After her husband's death, she ascended the throne and fiercely opposed the Doctrine of Lapse policy imposed by the British, which prevented her adopted son from inheriting the kingdom.\n",
        "In 1824, Rani Chennamma led an armed rebellion against the British East India Company, refusing to surrender her land. Despite initial victories, she was ultimately captured and imprisoned in Bailhongal Fort, where she died in 1829. Her resistance is seen as a precursor to India's independence movement, and she remains a symbol of courage and patriotism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dd508aa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd508aa9",
        "outputId": "1e7b3fb1-e899-4cd0-98c2-6dbe35e604b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob googletrans==3.1.0a0\n",
        "\n",
        "from textblob import TextBlob\n",
        "from googletrans import Translator\n",
        "\n",
        "# Sample text\n",
        "text = \"Rani Chennamma was the queen of Kittur, a princely state in present-day Karnataka, India. She is remembered as one of the earliest Indian rulers to fight against British colonial rule. Born in 1778, she was well-trained in horse riding, sword fighting, and archery. After her husband's death, she ascended the throne and fiercely opposed the Doctrine of Lapse policy imposed by the British, which prevented her adopted son from inheriting the kingdom. In 1824, Rani Chennamma led an armed rebellion against the British East India Company, refusing to surrender her land. Despite initial victories, she was ultimately captured and imprisoned in Bailhongal Fort, where she died in 1829. Her resistance is seen as a precursor to India's independence movement, and she remains a symbol of courage and patriotism.\"\n",
        "\n",
        "# Create a TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Detect the language using googletrans as a workaround\n",
        "translator = Translator()  # Create a Translator object\n",
        "detected = translator.detect(text)  # Detect the language\n",
        "\n",
        "print(\"Detected Language:\", detected.lang)  # Print the detected language code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNdoBgx_paTE",
        "outputId": "e9233c7d-f3a9-4c85-800e-bc510d9002b5"
      },
      "id": "WNdoBgx_paTE",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==3.1.0a0)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2025.1.31)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16352 sha256=bc16cd759caa57f92648d450f57242417512826590e217e4cec04df96f0e6a27\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f2/e0/d578821d723b473d18610ea93810e4a5402463919f07e603d9\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langsmith 0.3.5 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 1.61.1 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "Detected Language: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7437c41",
      "metadata": {
        "id": "a7437c41"
      },
      "source": [
        "#### Question:\n",
        "\n",
        "Flipkart has collected customer reviews for a smartphone. Your task is to train a sentiment analysis model using TextBlob's Naive Bayes Classifier to predict whether a given review is positive or negative.\n",
        "\n",
        "You have a dataset of 50 reviews, out of which 40 reviews are for training and 10 reviews are for testing. Train your model and evaluate its performance on the test data.\n",
        "\n",
        "\n",
        "\n",
        "##### Dataset (Train & Test)\n",
        "\n",
        "##### Training Data (40 Reviews)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "84edbb43",
      "metadata": {
        "id": "84edbb43"
      },
      "source": [
        "train = [\n",
        "    (\"This phone is amazing, I love the camera!\", \"pos\"),\n",
        "    (\"Battery life is superb, lasts more than a day.\", \"pos\"),\n",
        "    (\"The display quality is top-notch.\", \"pos\"),\n",
        "    (\"Fast charging works like a charm!\", \"pos\"),\n",
        "    (\"Very smooth performance and no lag.\", \"pos\"),\n",
        "    (\"Great phone at this price range.\", \"pos\"),\n",
        "    (\"I am highly satisfied with the features.\", \"pos\"),\n",
        "    (\"Audio quality is crystal clear.\", \"pos\"),\n",
        "    (\"Superb design and looks premium.\", \"pos\"),\n",
        "    (\"Face unlock is super fast.\", \"pos\"),\n",
        "    (\"I regret buying this phone, worst experience.\", \"neg\"),\n",
        "    (\"Battery drains too fast, not recommended.\", \"neg\"),\n",
        "    (\"Overheating issue while gaming, disappointing.\", \"neg\"),\n",
        "    (\"Camera quality is terrible in low light.\", \"neg\"),\n",
        "    (\"Too many ads in the UI, very annoying.\", \"neg\"),\n",
        "    (\"Fingerprint sensor is slow and unresponsive.\", \"neg\"),\n",
        "    (\"Touchscreen sometimes freezes.\", \"neg\"),\n",
        "    (\"Speaker volume is too low.\", \"neg\"),\n",
        "    (\"Performance is sluggish, lags a lot.\", \"neg\"),\n",
        "    (\"Build quality feels very cheap.\", \"neg\"),\n",
        "    (\"The phone is very lightweight and easy to hold.\", \"pos\"),\n",
        "    (\"I love the color and design of this phone.\", \"pos\"),\n",
        "    (\"The UI is clean and easy to use.\", \"pos\"),\n",
        "    (\"Gaming performance is fantastic.\", \"pos\"),\n",
        "    (\"Storage capacity is more than enough.\", \"pos\"),\n",
        "    (\"This phone is a complete package!\", \"pos\"),\n",
        "    (\"Good for video calling, camera quality is decent.\", \"pos\"),\n",
        "    (\"5G connectivity works smoothly.\", \"pos\"),\n",
        "    (\"This phone exceeded my expectations.\", \"pos\"),\n",
        "    (\"The processor is fast and efficient.\", \"pos\"),\n",
        "    (\"Network issues, keeps disconnecting.\", \"neg\"),\n",
        "    (\"Screen started flickering after a few days.\", \"neg\"),\n",
        "    (\"The phone heats up even with normal usage.\", \"neg\"),\n",
        "    (\"No software updates, outdated security patches.\", \"neg\"),\n",
        "    (\"Customer support is unhelpful.\", \"neg\"),\n",
        "    (\"Charger stopped working within a month.\", \"neg\"),\n",
        "    (\"Speakers produce distorted sound.\", \"neg\"),\n",
        "    (\"Camera app crashes frequently.\", \"neg\"),\n",
        "    (\"Poor optimization, apps take forever to load.\", \"neg\"),\n",
        "    (\"Too heavy to hold for long hours.\", \"neg\")\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4cd26d",
      "metadata": {
        "id": "4c4cd26d"
      },
      "source": [
        "###### Testing Data (10 Reviews)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "3d5805c1",
      "metadata": {
        "id": "3d5805c1"
      },
      "source": [
        "test = [\n",
        "    (\"I love the camera, it clicks amazing pictures!\", \"pos\"),\n",
        "    (\"Battery backup is disappointing, drains quickly.\", \"neg\"),\n",
        "    (\"The display is very bright and vibrant.\", \"pos\"),\n",
        "    (\"Phone lags when switching between apps.\", \"neg\"),\n",
        "    (\"Very stylish and premium-looking design.\", \"pos\"),\n",
        "    (\"Face unlock doesn't work properly.\", \"neg\"),\n",
        "    (\"The performance is super smooth!\", \"pos\"),\n",
        "    (\"Charging speed is very slow, takes ages.\", \"neg\"),\n",
        "    (\"Call quality is excellent, voice is very clear.\", \"pos\"),\n",
        "    (\"The phone keeps hanging, very frustrating.\", \"neg\")\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8215d55c",
      "metadata": {
        "id": "8215d55c"
      },
      "source": [
        "###### Your Task:    \n",
        "    - Train a Naive Bayes Classifier using textblob.classifiers.NaiveBayesClassifier on the training dataset.\n",
        "    - Predict sentiment (positive or negative) for the test data.\n",
        "    - Evaluate model accuracy and analyze the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "7CWDUSlBH_pS"
      },
      "id": "7CWDUSlBH_pS",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob.classifiers import NaiveBayesClassifier"
      ],
      "metadata": {
        "id": "JmEMbAbIIIuF"
      },
      "id": "JmEMbAbIIIuF",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YSqImmaJkkZ",
        "outputId": "120b2512-32aa-4ef8-af9e-32ddfcd53c15"
      },
      "id": "0YSqImmaJkkZ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading nltk data\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNFO6ZEqIS2z",
        "outputId": "dccfdc3d-15a1-4665-d0cf-0d74c6b1e0f9"
      },
      "id": "wNFO6ZEqIS2z",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data (40 Reviews)\n",
        "train = [\n",
        "    (\"This phone is amazing, I love the camera!\", \"pos\"),\n",
        "    (\"Battery life is superb, lasts more than a day.\", \"pos\"),\n",
        "    (\"The display quality is top-notch.\", \"pos\"),\n",
        "    (\"Fast charging works like a charm!\", \"pos\"),\n",
        "    (\"Very smooth performance and no lag.\", \"pos\"),\n",
        "    (\"Great phone at this price range.\", \"pos\"),\n",
        "    (\"I am highly satisfied with the features.\", \"pos\"),\n",
        "    (\"Audio quality is crystal clear.\", \"pos\"),\n",
        "    (\"Superb design and looks premium.\", \"pos\"),\n",
        "    (\"Face unlock is super fast.\", \"pos\"),\n",
        "    (\"I regret buying this phone, worst experience.\", \"neg\"),\n",
        "    (\"Battery drains too fast, not recommended.\", \"neg\"),\n",
        "    (\"Overheating issue while gaming, disappointing.\", \"neg\"),\n",
        "    (\"Camera quality is terrible in low light.\", \"neg\"),\n",
        "    (\"Too many ads in the UI, very annoying.\", \"neg\"),\n",
        "    (\"Fingerprint sensor is slow and unresponsive.\", \"neg\"),\n",
        "    (\"Touchscreen sometimes freezes.\", \"neg\"),\n",
        "    (\"Speaker volume is too low.\", \"neg\"),\n",
        "    (\"Performance is sluggish, lags a lot.\", \"neg\"),\n",
        "    (\"Build quality feels very cheap.\", \"neg\"),\n",
        "    (\"The phone is very lightweight and easy to hold.\", \"pos\"),\n",
        "    (\"I love the color and design of this phone.\", \"pos\"),\n",
        "    (\"The UI is clean and easy to use.\", \"pos\"),\n",
        "    (\"Gaming performance is fantastic.\", \"pos\"),\n",
        "    (\"Storage capacity is more than enough.\", \"pos\"),\n",
        "    (\"This phone is a complete package!\", \"pos\"),\n",
        "    (\"Good for video calling, camera quality is decent.\", \"pos\"),\n",
        "    (\"5G connectivity works smoothly.\", \"pos\"),\n",
        "    (\"This phone exceeded my expectations.\", \"pos\"),\n",
        "    (\"The processor is fast and efficient.\", \"pos\"),\n",
        "    (\"Network issues, keeps disconnecting.\", \"neg\"),\n",
        "    (\"Screen started flickering after a few days.\", \"neg\"),\n",
        "    (\"The phone heats up even with normal usage.\", \"neg\"),\n",
        "    (\"No software updates, outdated security patches.\", \"neg\"),\n",
        "    (\"Customer support is unhelpful.\", \"neg\"),\n",
        "    (\"Charger stopped working within a month.\", \"neg\"),\n",
        "    (\"Speakers produce distorted sound.\", \"neg\"),\n",
        "    (\"Camera app crashes frequently.\", \"neg\"),\n",
        "    (\"Poor optimization, apps take forever to load.\", \"neg\"),\n",
        "    (\"Too heavy to hold for long hours.\", \"neg\")\n",
        "]"
      ],
      "metadata": {
        "id": "FIJenScGIuH1"
      },
      "id": "FIJenScGIuH1",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Data (10 Reviews)\n",
        "test = [\n",
        "    (\"I love the camera, it clicks amazing pictures!\", \"pos\"),\n",
        "    (\"Battery backup is disappointing, drains quickly.\", \"neg\"),\n",
        "    (\"The display is very bright and vibrant.\", \"pos\"),\n",
        "    (\"Phone lags when switching between apps.\", \"neg\"),\n",
        "    (\"Very stylish and premium-looking design.\", \"pos\"),\n",
        "    (\"Face unlock doesn't work properly.\", \"neg\"),\n",
        "    (\"The performance is super smooth!\", \"pos\"),\n",
        "    (\"Charging speed is very slow, takes ages.\", \"neg\"),\n",
        "    (\"Call quality is excellent, voice is very clear.\", \"pos\"),\n",
        "    (\"The phone keeps hanging, very frustrating.\", \"neg\")\n",
        "]"
      ],
      "metadata": {
        "id": "jbgO2p4zIuo8"
      },
      "id": "jbgO2p4zIuo8",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Naive Bayes Classifier\n",
        "classifier = NaiveBayesClassifier(train)"
      ],
      "metadata": {
        "id": "ghBXevSWJF6r"
      },
      "id": "ghBXevSWJF6r",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "accuracy = classifier.accuracy(test)"
      ],
      "metadata": {
        "id": "pFndRgm6JYlK"
      },
      "id": "pFndRgm6JYlK",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sentiment for each test review\n",
        "predictions = [(review[0], classifier.classify(review[0])) for review in test]\n"
      ],
      "metadata": {
        "id": "JCZpI-HwJ2vU"
      },
      "id": "JCZpI-HwJ2vU",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"\\nPredictions:\")\n",
        "for review, sentiment in predictions:\n",
        "    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ13hiQJJ3dl",
        "outputId": "a5279951-4566-4072-b585-dab3b1909456"
      },
      "id": "LQ13hiQJJ3dl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 90.00%\n",
            "\n",
            "Predictions:\n",
            "Review: I love the camera, it clicks amazing pictures!\n",
            "Predicted Sentiment: pos\n",
            "\n",
            "Review: Battery backup is disappointing, drains quickly.\n",
            "Predicted Sentiment: neg\n",
            "\n",
            "Review: The display is very bright and vibrant.\n",
            "Predicted Sentiment: pos\n",
            "\n",
            "Review: Phone lags when switching between apps.\n",
            "Predicted Sentiment: neg\n",
            "\n",
            "Review: Very stylish and premium-looking design.\n",
            "Predicted Sentiment: pos\n",
            "\n",
            "Review: Face unlock doesn't work properly.\n",
            "Predicted Sentiment: pos\n",
            "\n",
            "Review: The performance is super smooth!\n",
            "Predicted Sentiment: pos\n",
            "\n",
            "Review: Charging speed is very slow, takes ages.\n",
            "Predicted Sentiment: neg\n",
            "\n",
            "Review: Call quality is excellent, voice is very clear.\n",
            "Predicted Sentiment: pos\n",
            "\n",
            "Review: The phone keeps hanging, very frustrating.\n",
            "Predicted Sentiment: neg\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}